{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probe Data - Map Matching\n",
    "## Nick Paras | Kapil Garg\n",
    "\n",
    "### Assignment 2\n",
    "\n",
    "Input: Probe data and map [probe_data_map_matching.rar](https://canvas.northwestern.edu/courses/51440/files/3334329/download?wrap=1)\n",
    "\n",
    "-The raw probe points in Germany collected in 9 months\n",
    "\n",
    "-The link data for the links that probe points can be map-matched to.\n",
    "\n",
    "Tasks:\n",
    "-- map match probe points to road links\n",
    "\n",
    "-- derive road slope for each road link\n",
    "\n",
    "-- evaluate the derived road slope with the surveyed road slope in the link data file\n",
    "\n",
    "**Please submit your code and slides presentation of your approach and results including evaluation comparing with the slopes in the link data file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "We use **Python 3.6** and rely on the dependencies:\n",
    "* numpy\n",
    "* scikit-learn\n",
    "* matplotlib\n",
    "* pandas\n",
    "\n",
    "We also use Jupyter Notebooks for our code and reports. For quick setup, please create a conda environment with the following:\n",
    "\n",
    "    $ conda create --name probe-data pandas matplotlib numpy scikit-learn\n",
    "\n",
    "and then activate the conda environment with\n",
    "\n",
    "    $ source activate probe-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "import operator\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "import time\n",
    "import json\n",
    "import gmplot\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from haversine import haversine\n",
    "from functools import reduce\n",
    "from IPython.display import IFrame\n",
    "from collections import namedtuple\n",
    "\n",
    "# Custom classes\n",
    "import link_classes as lc\n",
    "import graph_classes as graph\n",
    "\n",
    "from dist_functions import dist_to_link as link_dist\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Constants\n",
    "DATA_DIR = '../data'\n",
    "GOOGLE_MAPS_KEY = ''\n",
    "with open('config.json') as data_file:\n",
    "    data = json.load(data_file)\n",
    "    GOOGLE_MAPS_KEY = data['google-maps-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def bearing(start, end):\n",
    "    \"\"\"\n",
    "    Computes the bearing in degrees between two geopoints\n",
    "    \n",
    "    Inputs:\n",
    "        start (tuple of lat, long): starting geolocation\n",
    "        end (tuple of lat, long): ending geolocation\n",
    "    \n",
    "    Outputs:\n",
    "        (float): bearing in degrees between start and end\n",
    "    \"\"\"\n",
    "    phi_1 = math.radians(start[0])\n",
    "    phi_2 = math.radians(end[0])\n",
    "    lambda_1 = math.radians(start[1])\n",
    "    lambda_2 = math.radians(end[1])\n",
    "    \n",
    "    x = math.cos(phi_2) * math.sin(lambda_2 - lambda_1)\n",
    "    y = math.cos(phi_1) * math.sin(phi_2) - (math.sin(phi_1) * math.cos(phi_2) * math.cos(lambda_2 - lambda_1))\n",
    "\n",
    "    return (math.degrees(math.atan2(x, y)) + 360) % 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Probe Data for Map Matching\n",
    "\n",
    "Here we'll load our data from the two csv's into Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampleID</th>\n",
       "      <th>dateTime</th>\n",
       "      <th>sourceCode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>altitude</th>\n",
       "      <th>speed</th>\n",
       "      <th>heading</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3496</td>\n",
       "      <td>2009-06-12 06:12:49</td>\n",
       "      <td>13</td>\n",
       "      <td>51.496868</td>\n",
       "      <td>9.386022</td>\n",
       "      <td>200</td>\n",
       "      <td>23</td>\n",
       "      <td>339</td>\n",
       "      <td>3496_6/12/2009 6:12:49 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3496</td>\n",
       "      <td>2009-06-12 06:12:54</td>\n",
       "      <td>13</td>\n",
       "      <td>51.496682</td>\n",
       "      <td>9.386157</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>129</td>\n",
       "      <td>3496_6/12/2009 6:12:54 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3496</td>\n",
       "      <td>2009-06-12 06:12:59</td>\n",
       "      <td>13</td>\n",
       "      <td>51.496705</td>\n",
       "      <td>9.386422</td>\n",
       "      <td>201</td>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "      <td>3496_6/12/2009 6:12:59 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3496</td>\n",
       "      <td>2009-06-12 06:13:04</td>\n",
       "      <td>13</td>\n",
       "      <td>51.496749</td>\n",
       "      <td>9.386840</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>3496_6/12/2009 6:13:04 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3496</td>\n",
       "      <td>2009-06-12 06:13:09</td>\n",
       "      <td>13</td>\n",
       "      <td>51.496864</td>\n",
       "      <td>9.387294</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>3496_6/12/2009 6:13:09 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sampleID            dateTime  sourceCode   latitude  longitude  altitude  \\\n",
       "0      3496 2009-06-12 06:12:49          13  51.496868   9.386022       200   \n",
       "1      3496 2009-06-12 06:12:54          13  51.496682   9.386157       200   \n",
       "2      3496 2009-06-12 06:12:59          13  51.496705   9.386422       201   \n",
       "3      3496 2009-06-12 06:13:04          13  51.496749   9.386840       201   \n",
       "4      3496 2009-06-12 06:13:09          13  51.496864   9.387294       199   \n",
       "\n",
       "   speed  heading                         id  \n",
       "0     23      339  3496_6/12/2009 6:12:49 AM  \n",
       "1     10      129  3496_6/12/2009 6:12:54 AM  \n",
       "2     21       60  3496_6/12/2009 6:12:59 AM  \n",
       "3      0      360  3496_6/12/2009 6:13:04 AM  \n",
       "4      0      360  3496_6/12/2009 6:13:09 AM  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_headers = ['sampleID', \n",
    "                 'dateTime', \n",
    "                 'sourceCode', \n",
    "                 'latitude', \n",
    "                 'longitude', \n",
    "                 'altitude', \n",
    "                 'speed', \n",
    "                 'heading']\n",
    "\n",
    "probe_data = pd.read_csv(os.path.join(DATA_DIR, 'Partition6467ProbePoints.csv'), header=None, names=probe_headers)\n",
    "probe_data.drop_duplicates(inplace=True)\n",
    "probe_data['id'] = probe_data['sampleID'].map(str) + '_' + probe_data['dateTime']\n",
    "probe_data['dateTime'] = pd.to_datetime(probe_data['dateTime'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "probe_data.sort_values(['sampleID', 'dateTime'], ascending=[True, True], inplace=True)\n",
    "probe_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linkPVID</th>\n",
       "      <th>refNodeID</th>\n",
       "      <th>nrefNodeID</th>\n",
       "      <th>length</th>\n",
       "      <th>functionalClass</th>\n",
       "      <th>directionOfTravel</th>\n",
       "      <th>speedCategory</th>\n",
       "      <th>fromRefSpeedLimit</th>\n",
       "      <th>toRefSpeedLimit</th>\n",
       "      <th>fromRefNumLanes</th>\n",
       "      <th>toRefNumLanes</th>\n",
       "      <th>multiDigitized</th>\n",
       "      <th>urban</th>\n",
       "      <th>timeZone</th>\n",
       "      <th>shapeInfo</th>\n",
       "      <th>curvatureInfo</th>\n",
       "      <th>slopeInfo</th>\n",
       "      <th>speedLimit</th>\n",
       "      <th>shapeArray</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62007637</td>\n",
       "      <td>162844982</td>\n",
       "      <td>162809070</td>\n",
       "      <td>335.04</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.4965800/9.3862299/|51.4994700/9.3848799/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>[[51.49658, 9.3862299], [51.49947, 9.3848799]]</td>\n",
       "      <td>[51.498025, 9.3855549]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>567329767</td>\n",
       "      <td>162844982</td>\n",
       "      <td>162981512</td>\n",
       "      <td>134.56</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.4965800/9.3862299/|51.4966899/9.3867100/|51...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[[51.49658, 9.3862299], [51.4966899, 9.38671],...</td>\n",
       "      <td>[51.496769975, 9.387074925]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62007648</td>\n",
       "      <td>162877732</td>\n",
       "      <td>162844982</td>\n",
       "      <td>97.01</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.4962899/9.3849100/|51.4965800/9.3862299/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>[[51.4962899, 9.38491], [51.49658, 9.3862299]]</td>\n",
       "      <td>[51.49643495, 9.38556995]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78670326</td>\n",
       "      <td>162877732</td>\n",
       "      <td>163152693</td>\n",
       "      <td>314.84</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.4962899/9.3849100/|51.4990000/9.3836099/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>[[51.4962899, 9.38491], [51.499, 9.3836099]]</td>\n",
       "      <td>[51.49764495, 9.38425995]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51881672</td>\n",
       "      <td>174713859</td>\n",
       "      <td>174587951</td>\n",
       "      <td>110.17</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0643099/8.7903400/45.79|53.0650299/8.791470...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00/-0.090|110.17/0.062</td>\n",
       "      <td>50</td>\n",
       "      <td>[[53.0643099, 8.79034], [53.0650299, 8.79147]]</td>\n",
       "      <td>[53.0646699, 8.790905]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    linkPVID  refNodeID  nrefNodeID  length  functionalClass  \\\n",
       "0   62007637  162844982   162809070  335.04                5   \n",
       "1  567329767  162844982   162981512  134.56                5   \n",
       "2   62007648  162877732   162844982   97.01                5   \n",
       "3   78670326  162877732   163152693  314.84                5   \n",
       "4   51881672  174713859   174587951  110.17                3   \n",
       "\n",
       "  directionOfTravel  speedCategory  fromRefSpeedLimit  toRefSpeedLimit  \\\n",
       "0                 B              7                 30               30   \n",
       "1                 B              7                  0                0   \n",
       "2                 B              7                 30               30   \n",
       "3                 B              7                 30               30   \n",
       "4                 B              6                 50               50   \n",
       "\n",
       "   fromRefNumLanes  toRefNumLanes multiDigitized urban  timeZone  \\\n",
       "0                0              0              F     T       0.0   \n",
       "1                0              0              F     T       0.0   \n",
       "2                0              0              F     T       0.0   \n",
       "3                0              0              F     T       0.0   \n",
       "4                2              2              F     T       0.0   \n",
       "\n",
       "                                           shapeInfo curvatureInfo  \\\n",
       "0        51.4965800/9.3862299/|51.4994700/9.3848799/           NaN   \n",
       "1  51.4965800/9.3862299/|51.4966899/9.3867100/|51...           NaN   \n",
       "2        51.4962899/9.3849100/|51.4965800/9.3862299/           NaN   \n",
       "3        51.4962899/9.3849100/|51.4990000/9.3836099/           NaN   \n",
       "4  53.0643099/8.7903400/45.79|53.0650299/8.791470...           NaN   \n",
       "\n",
       "                  slopeInfo  speedLimit  \\\n",
       "0                       NaN          30   \n",
       "1                       NaN           1   \n",
       "2                       NaN          30   \n",
       "3                       NaN          30   \n",
       "4  0.00/-0.090|110.17/0.062          50   \n",
       "\n",
       "                                          shapeArray  \\\n",
       "0     [[51.49658, 9.3862299], [51.49947, 9.3848799]]   \n",
       "1  [[51.49658, 9.3862299], [51.4966899, 9.38671],...   \n",
       "2     [[51.4962899, 9.38491], [51.49658, 9.3862299]]   \n",
       "3       [[51.4962899, 9.38491], [51.499, 9.3836099]]   \n",
       "4     [[53.0643099, 8.79034], [53.0650299, 8.79147]]   \n",
       "\n",
       "                      location  \n",
       "0       [51.498025, 9.3855549]  \n",
       "1  [51.496769975, 9.387074925]  \n",
       "2    [51.49643495, 9.38556995]  \n",
       "3    [51.49764495, 9.38425995]  \n",
       "4       [53.0646699, 8.790905]  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_headers = ['linkPVID', \n",
    "                'refNodeID', \n",
    "                'nrefNodeID', \n",
    "                'length', \n",
    "                'functionalClass', \n",
    "                'directionOfTravel', \n",
    "                'speedCategory', \n",
    "                'fromRefSpeedLimit', \n",
    "                'toRefSpeedLimit', \n",
    "                'fromRefNumLanes', \n",
    "                'toRefNumLanes', \n",
    "                'multiDigitized', \n",
    "                'urban', \n",
    "                'timeZone', \n",
    "                'shapeInfo', \n",
    "                'curvatureInfo', \n",
    "                'slopeInfo']\n",
    "\n",
    "# load raw link data\n",
    "link_data = pd.read_csv(os.path.join(DATA_DIR, 'Partition6467LinkData.csv'), header=None, names=link_headers)\n",
    "link_data['speedLimit'] = link_data[['fromRefSpeedLimit', 'toRefSpeedLimit']].max(axis=1)\n",
    "link_data.loc[link_data['speedLimit'] == 0, 'speedLimit'] = 1\n",
    "link_data['shapeArray'] = link_data['shapeInfo'].apply(lambda x: [[float(j) for j in i.split('/')[:2]] for i in x.split('|')])\n",
    "link_data['location'] = link_data['shapeArray'].apply(lambda x: reduce(np.add, x) / len(x))\n",
    "link_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create link data lookup dictionary\n",
    "links = []\n",
    "link_db = lc.LinkDatabase()\n",
    "with open(os.path.join(DATA_DIR, 'Partition6467LinkData.csv'), 'r') as csvfile:\n",
    "    rdr = csv.DictReader(csvfile, delimiter=',', fieldnames=link_headers)\n",
    "    for r in rdr:\n",
    "        rl = lc.RoadLink(r)\n",
    "        links.append(rl)\n",
    "        link_db.insert_link(rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create road link graph\n",
    "node_id_map = {}\n",
    "with open(os.path.join(DATA_DIR, 'Partition6467LinkData.csv'), 'r') as csvfile:\n",
    "    rdr = csv.DictReader(csvfile, delimiter=',', fieldnames=link_headers)\n",
    "    for r in rdr:\n",
    "        try:\n",
    "            node_id_map[r['refNodeID']] += [r['linkPVID']]\n",
    "        except KeyError:\n",
    "            node_id_map[r['refNodeID']] = [r['linkPVID']]\n",
    "\n",
    "road_graph = graph.RoadNetwork(node_id_map)\n",
    "with open(os.path.join(DATA_DIR, 'Partition6467LinkData.csv'), 'r') as csvfile:\n",
    "    rdr = csv.DictReader(csvfile, delimiter=',', fieldnames=link_headers)\n",
    "    for r in rdr:\n",
    "        road_graph.insert(graph.RoadNetworkNode(node_id_map, \\\n",
    "                                                [[float(j) for j in i.split('/')[:2]] for i in r['shapeInfo'].split('|')], \\\n",
    "                                                r['linkPVID'], \\\n",
    "                                                r['nrefNodeID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ST-Matching Algorithm\n",
    "Below is an implementation of the ST-Matching algorithm from the [Map-Matching for Low_sampling-Rate GPS Trajectories](https://www.microsoft.com/en-us/research/publication/map-matching-for-low-sampling-rate-gps-trajectories/?from=http%3A%2F%2Fresearch.microsoft.com%2Fapps%2Fpubs%2Fdefault.aspx%3Fid%3D105051) paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining useful utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Candidate = namedtuple('Candidate', ['linkPVID', 'location', 'speedLimit'])\n",
    "\n",
    "def nearest_n_segments(lat, long, n):\n",
    "    \"\"\"\n",
    "    Uses link_db to find nearest n road segments\n",
    "    \n",
    "    Inputs:\n",
    "        lat (float): latitude of probe point\n",
    "        lon (float): longitude of probe point\n",
    "        n (int): number of roads road segments to return\n",
    "        \n",
    "    Output: \n",
    "        (list of Candidate tuples): Candidate tuples of n-nearest road segments \n",
    "        \n",
    "    \"\"\"\n",
    "    # find nearest n links\n",
    "    output = []\n",
    "    try:\n",
    "        link_search = [(x, haversine(x.avgLatLong, (lat, long))) for x in link_db.get_links(lat, long)]\n",
    "        link_search.sort(key=operator.itemgetter(1))\n",
    "        link_search = link_search[0:n]\n",
    "\n",
    "        # extract only link PVIDs from search\n",
    "        output = [(int(x[0].linkPVID), x[1]) for x in link_search]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    # format output with additional data\n",
    "    for i in range(len(output)):\n",
    "        link_information = link_data[link_data['linkPVID'] == output[i][0]]\n",
    "        formatted_output = Candidate(int(link_information['linkPVID']), \\\n",
    "                                     list(link_information['location'])[0], \\\n",
    "                                    float(link_information['speedLimit']))\n",
    "        output[i] = formatted_output\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining scoring functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def observation_probability(p, c):\n",
    "    \"\"\"\n",
    "    Compute the likelihood that a GPS point p matches a candidate point c based on the distance between the two.\n",
    "    \n",
    "    Inputs:\n",
    "        p (tuple of lat, long): probe point\n",
    "        c (tuple of lat, long): candidate point\n",
    "    \n",
    "    Output:\n",
    "        (float): probability of the above\n",
    "    \"\"\"\n",
    "    distance = haversine(p, c)\n",
    "    return (1 / math.sqrt(2 * math.pi * 20)) * math.exp((distance**2) / (2 * 20**2))\n",
    "\n",
    "def transmission_probability(p_prev, p_curr, c_prev, c_curr):\n",
    "    \"\"\"\n",
    "    Compute the likelihood that the true path from p_prev to p_curr follows the shortest path from c_prev to c_curr\n",
    "    \n",
    "    Inputs:\n",
    "        p_prev (tuple of lat, long): previous probe point\n",
    "        p_curr (tuple of lat, long): current probe point\n",
    "        c_prev (tuple of lat, long): candidate point for previous probe point\n",
    "        c_curr (tuple of lat, long): candidate point for current probe point\n",
    "    \n",
    "    Output:\n",
    "        (float): probability of the above\n",
    "    \"\"\"\n",
    "    p_dist = haversine(p_prev, p_curr)\n",
    "    c_dist = haversine(c_prev, c_curr)\n",
    "    \n",
    "    if c_dist == 0:\n",
    "        return 1\n",
    "    \n",
    "    return p_dist / c_dist\n",
    "\n",
    "def spatial_analysis(p_prev, p_curr, c_prev, c_curr):\n",
    "    \"\"\"\n",
    "    Compute the spatial measurement value for two neighboring probe points p_prev and p_curr for\n",
    "    two candidate points c_prev, c_curr\n",
    "    \n",
    "    Inputs:\n",
    "        p_prev (tuple of lat, long): previous probe point\n",
    "        p_curr (tuple of lat, long): current probe point\n",
    "        c_prev (tuple of lat, long): candidate point for previous probe point\n",
    "        c_curr (tuple of lat, long): candidate point for current probe point\n",
    "    \n",
    "    Output:\n",
    "        (float): spatial measurement value\n",
    "    \"\"\"\n",
    "    return observation_probability(p_curr, c_curr) * transmission_probability(p_prev, p_curr, c_prev, c_curr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cosine_dist(a, b):\n",
    "    \"\"\"\n",
    "    Compute cosine distance between vectors a, b\n",
    "    \n",
    "    Input:\n",
    "        a (numpy array): vector a\n",
    "        b (numpy array): vector b\n",
    "    \n",
    "    Output:\n",
    "        (float): cosine distance between a, b\n",
    "    \"\"\"\n",
    "    numerator = np.sum(a * b)\n",
    "    denominator = math.sqrt(np.sum(a ** 2)) * math.sqrt(np.sum(b ** 2))\n",
    "    return numerator / denominator\n",
    "\n",
    "def temporal_analysis(p_prev, p_curr, c_prev, c_curr, speed_prev, speed_curr, delta_t):\n",
    "    \"\"\"\n",
    "    Compute the temporal meaurement value for two neighboring probe points and their candidate points c_prev, c_curr\n",
    "    \n",
    "    Inputs:\n",
    "        c_prev (tuple of lat, long): candidate point for previous probe point\n",
    "        c_curr (tuple of lat, long): candidate point for current probe point \n",
    "        speed_prev (float): speed limit of previous road segment\n",
    "        speed_curr (float): speed limit of current road segment\n",
    "        delta_t (float): time between previous probe and current probe point measurments\n",
    "        \n",
    "    Output:\n",
    "        (float): temporal measurment value\n",
    "    \"\"\"\n",
    "    avg_speed = haversine(c_prev, c_curr) / delta_t\n",
    "    if avg_speed == 0:\n",
    "        avg_speed = haversine(p_prev, p_curr) / delta_t\n",
    "    return cosine_dist(np.array([avg_speed, avg_speed]), np.array([speed_prev, speed_curr]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ST Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def st_function(p_prev, p_curr, c_prev, c_curr, speed_prev, speed_curr, delta_t):\n",
    "    \"\"\"\n",
    "    Computes st measurement\n",
    "    \n",
    "    Inputs: \n",
    "        p_prev (tuple of lat, long): previous probe point\n",
    "        p_curr (tuple of lat, long): current probe point\n",
    "        c_prev (tuple of lat, long): candidate point for previous probe point\n",
    "        c_curr (tuple of lat, long): candidate point for current probe point \n",
    "        speed_prev (float): speed limit of previous road segment\n",
    "        speed_curr (float): speed limit of current road segment\n",
    "        delta_t (float): time between previous probe and current probe point measurments\n",
    "        \n",
    "    Output:\n",
    "        (float): st measurement\n",
    "    \"\"\"\n",
    "    return spatial_analysis(p_prev, p_curr, c_prev, c_curr) * \\\n",
    "           temporal_analysis(p_prev, p_curr, c_prev, c_curr, speed_prev, speed_curr, delta_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_candidates(sample_id, location, delta_t):\n",
    "    \"\"\"\n",
    "    Finds nearest candidates for probe data point\n",
    "    \n",
    "    Input: \n",
    "        sample_id (string): sample_id\n",
    "        location (tuple): (lat, long)\n",
    "        delta_t (float): time diff with last probe\n",
    "        \n",
    "    Output: \n",
    "        (tuple): (sample_id, (lat, long), delta_t, [Candidates])\n",
    "    \"\"\"\n",
    "    return (sample_id, location, delta_t, nearest_n_segments(location[0], location[1], 3))\n",
    "\n",
    "def st_matching_algorithm(sample):\n",
    "    \"\"\"\n",
    "    Match trajectory points to road links\n",
    "    \n",
    "    Input:\n",
    "        sample (pandas dataframe): probe data matching a sample id\n",
    "    \n",
    "    Output: \n",
    "        (list of tuples): list of tuples (sample_id, linkPVID)\n",
    "    \"\"\"\n",
    "    # get list of candidate points\n",
    "    candidates_for_id = [None for x in range(len(sample))]\n",
    "    sample_ids = [None for x in range(len(sample))]\n",
    "    counter = 0\n",
    "    \n",
    "    for row in sample.itertuples():\n",
    "        delta_t = 0\n",
    "        try:\n",
    "            delta_t = (sample.loc[row.Index, 'dateTime'] - sample.loc[row.Index - 1, 'dateTime']).seconds\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "        candidates_for_id[counter] = find_candidates(row.id, (row.latitude, row.longitude), delta_t)\n",
    "        sample_ids[counter] = row.id\n",
    "        counter += 1\n",
    "\n",
    "    # find matched sequence    \n",
    "    matched_sequence = find_matched_sequence(candidates_for_id)\n",
    "    \n",
    "    # zip together sample_id and linkPVID\n",
    "    return zip(sample_ids, matched_sequence)\n",
    "\n",
    "def find_matched_sequence(candidates):\n",
    "    \"\"\"\n",
    "    Find longest matching sequence given candidates\n",
    "    \n",
    "    Input:\n",
    "        candidates (list of tuple): see find_candidates\n",
    "    \n",
    "    Output:\n",
    "       (list of tuples): list of tuples (sample_id, linkPVID) \n",
    "    \"\"\"\n",
    "    # setup variables \n",
    "    parents = [{str(i.linkPVID): None for i in candidate[3]} for candidate in candidates]\n",
    "    f = [{str(i.linkPVID): 0 for i in candidate[3]} for candidate in candidates]\n",
    "    candidate_count = len(candidates)\n",
    "    \n",
    "    # set f[0] equal to observation probability\n",
    "    for c in candidates[0][3]:\n",
    "        f[0][str(c.linkPVID)] = observation_probability(candidates[0][1], c.location)\n",
    "    \n",
    "    # compute scores for each node\n",
    "    for i in range(1, candidate_count):\n",
    "        for cs in candidates[i][3]:\n",
    "            max_val = -math.inf\n",
    "            for ct in candidates[i - 1][3]:\n",
    "                # check if cs is a valid neighbor of ct\n",
    "                if (str(cs.linkPVID) != str(ct.linkPVID)) and (str(cs.linkPVID) not in road_graph.nodes[str(ct.linkPVID)].neighbors):\n",
    "                    f[i][str(cs.linkPVID)] = max_val\n",
    "                    continue\n",
    "                    \n",
    "                # define all the variables then compute new score\n",
    "                p_prev = candidates[i - 1][1]\n",
    "                p_curr = candidates[i][1]\n",
    "                c_prev = ct.location\n",
    "                c_curr = cs.location\n",
    "                speed_prev = ct.speedLimit\n",
    "                speed_curr = cs.speedLimit\n",
    "                delta_t = candidates[i][2]\n",
    "                \n",
    "                alt = f[i - 1][str(ct.linkPVID)] + st_function(p_prev, p_curr, c_prev, c_curr, speed_prev, speed_curr, delta_t)\n",
    "                \n",
    "                # check if higher than existing\n",
    "                if alt > max_val:\n",
    "                    max_val = alt\n",
    "                    parents[i][str(cs.linkPVID)] = ct.linkPVID\n",
    "                \n",
    "                # set max value for current node\n",
    "                f[i][str(cs.linkPVID)] = max_val\n",
    "        \n",
    "\n",
    "    # compute path\n",
    "    r_list = []\n",
    "    c = max(f[candidate_count - 1], key=f[candidate_count - 1].get)\n",
    "    for i in range(candidate_count - 1, 0, -1):\n",
    "        r_list.append(c)\n",
    "        c = parents[i][str(c)]\n",
    "    r_list.append(c)\n",
    "    \n",
    "    return r_list[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'None'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-235-d9f1593749e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst_matching_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobe_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprobe_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sampleID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4552\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstacked_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mprobe_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linkPVID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-231-a0da5eac5f9e>\u001b[0m in \u001b[0;36mst_matching_algorithm\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# find matched sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmatched_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_matched_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates_for_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# zip together sample_id and linkPVID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-231-a0da5eac5f9e>\u001b[0m in \u001b[0;36mfind_matched_sequence\u001b[0;34m(candidates)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_count\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mr_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0mr_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'None'"
     ]
    }
   ],
   "source": [
    "temp = st_matching_algorithm(probe_data[probe_data['sampleID'] == 4552])\n",
    "stacked_values = np.dstack(temp)[0]\n",
    "\n",
    "try:\n",
    "    del probe_data['linkPVID']\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "probe_data = probe_data.merge(pd.DataFrame({'id': stacked_values[0], 'linkPVID': stacked_values[1]}), how='left', on=['id'])\n",
    "probe_data['linkPVID'].fillna(0, inplace=True)\n",
    "probe_data['linkPVID'] = probe_data['linkPVID'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2601946830749512 minutes for 1000 data points using 8 CPU threads.\n"
     ]
    }
   ],
   "source": [
    "# time code\n",
    "t0 = time.time()\n",
    "\n",
    "# sample only first sample_size to make computation faster\n",
    "sample_size = 1000\n",
    "# sample_size = len(probe_data) # for all data\n",
    "\n",
    "# add road link\n",
    "probe_data['linkPVID'] = 0\n",
    "\n",
    "# parallelizable function\n",
    "def link_road_parallel(indicies):\n",
    "    \"\"\"\n",
    "    Links road to probe for set of indicies\n",
    "    \n",
    "    Input:\n",
    "        indicies (list of floats): indicies to find nearest link for\n",
    "    \"\"\"\n",
    "    output = [(0, 0) for x in range(indicies[1] - indicies[0])]\n",
    "    n = 3\n",
    "    counter = 0\n",
    "    for row in probe_data[indicies[0]:indicies[1]].itertuples():\n",
    "        output[counter] = (row.Index, closest_by_heading(nearest_n_segments(row.latitude, row.longitude, n),\n",
    "                                                         row.heading))\n",
    "        counter += 1\n",
    "    \n",
    "    return output\n",
    "\n",
    "# run in parallel\n",
    "N_CORES = mp.cpu_count()\n",
    "C_SIZE = math.ceil(sample_size / N_CORES)\n",
    "\n",
    "pool = mp.Pool(N_CORES)\n",
    "r = pool.map(link_road_parallel, [[(C_SIZE * i), ((i + 1) * C_SIZE)] for i in range(N_CORES)])\n",
    "linkings = list(itertools.chain.from_iterable(r))\n",
    "\n",
    "# assign values to probe_data\n",
    "stacked_values = np.dstack(linkings)[0]\n",
    "probe_data.loc[stacked_values[0], 'linkPVID'] = stacked_values[1]\n",
    "        \n",
    "# finish timing\n",
    "t1 = time.time()\n",
    "print(str((t1 - t0) / 60) + ' minutes for ' + str(sample_size) + ' data points using ' + str(N_CORES) + ' CPU threads.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probe_data[0:sample_size].to_csv('./sample_linked_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output file\n",
    "The output file has the following columns (columns in **bold** are pulled from the LinkData csv):\n",
    "- sampleID: a unique identifier for the set of probe points that were collected from a particular phone.\n",
    "- dateTime: date and time that the probe point was collected.\n",
    "- sourceCode: a unique identifier for the data supplier (13 = Nokia).\n",
    "- latitude: latitude in decimal degrees.\n",
    "- longitude: longitude in decimal degrees.\n",
    "- altitude: altitude in meters.\n",
    "- speed: speed in KPH.\n",
    "- heading: heading in degrees.\n",
    "- linkPVID: published versioned identifier for the link.\n",
    "- **direction**: direction the vehicle was travelling on thelink (F = from ref node, T = towards ref node).\n",
    "- **distFromRef**: distance from the reference node to the map-matched probe point location on the link in decimal meters.\n",
    "- **distFromLink**: perpendicular distance from the map-matched probe point location on the link to the probe point in decimal meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data\n",
    "Now, we plot both the probe data with its associated links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_map_plot(method, sample_id, gmaps_api_key, data):\n",
    "    probe_plot_data = data[(data['linkPVID'] != 0) & (data['sampleID'] == sample_id)]\n",
    "\n",
    "    # create map object centered at mean lat, long\n",
    "    gmap = gmplot.GoogleMapPlotter(np.mean(probe_plot_data['latitude']), np.mean(probe_plot_data['longitude']), 16)\n",
    "\n",
    "    # plot data with color-coded probes and links\n",
    "    unique_links = probe_plot_data['linkPVID'].unique()\n",
    "    colors = list(gmap.color_dict.keys())[0:-1]\n",
    "    color_index = 0\n",
    "\n",
    "    for i in unique_links:\n",
    "        # setup variables\n",
    "        current_color = colors[color_index]\n",
    "        probe_lats = probe_plot_data[probe_plot_data['linkPVID'] == i]['latitude']\n",
    "        probe_longs = probe_plot_data[probe_plot_data['linkPVID'] == i]['longitude']\n",
    "\n",
    "        link_lats = [x[0] for x in list(link_data[link_data['linkPVID'] == i]['shapeArray'])[0]]\n",
    "        link_longs = [x[1] for x in list(link_data[link_data['linkPVID'] == i]['shapeArray'])[0]]\n",
    "        \n",
    "        gmap.scatter(probe_lats, probe_longs, marker=False, color=current_color, s=5)\n",
    "        gmap.plot(link_lats, link_longs, color=current_color, edge_width=10, alpha=0.25)\n",
    "\n",
    "        color_index = (color_index + 1) % len(colors)\n",
    "        print('Link Segment: ' + str(i) + ', Color: ' + str(current_color))\n",
    "    \n",
    "    # print out file\n",
    "    if not os.path.exists('./graphs'):\n",
    "        os.makedirs('./graphs')\n",
    "    file_name = './graphs/' + method + '_' + str(sample_id) + '.html'\n",
    "    gmap.draw(file_name)\n",
    "\n",
    "    def insertapikey(fname, apikey):\n",
    "        \"\"\"put the google api key in a html file\"\"\"\n",
    "        def putkey(htmltxt, apikey, apistring=None):\n",
    "            \"\"\"put the apikey in the htmltxt and return soup\"\"\"\n",
    "            if not apistring:\n",
    "                apistring = 'https://maps.googleapis.com/maps/api/js?key=%s&callback=initMap'\n",
    "            soup = BeautifulSoup(htmltxt, 'html.parser')\n",
    "            body = soup.body\n",
    "            src = apistring % (apikey, )\n",
    "            tscript = soup.new_tag('script', src=src, async='defer')\n",
    "            body.insert(-1, tscript)\n",
    "            return soup\n",
    "        htmltxt = open(fname, 'r').read()\n",
    "        soup = putkey(htmltxt, apikey)\n",
    "        newtxt = soup.prettify()\n",
    "        open(fname, 'w').write(newtxt)\n",
    "\n",
    "    insertapikey(file_name, gmaps_api_key)\n",
    "    return IFrame(file_name, width=985, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link Segment: 62007648, Color: b\n",
      "Link Segment: 62007637, Color: g\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"985\"\n",
       "            height=\"700\"\n",
       "            src=\"./graphs/st-matching_3496.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x18d895dd8>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select data to plot\n",
    "sample_id = 3496\n",
    "make_map_plot('st-matching', sample_id, GOOGLE_MAPS_KEY, probe_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probe-data",
   "language": "python",
   "name": "probe-data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
